
---

```md
# ğŸ§  Intelligent Data Analysis Platform

An advanced, **AI-driven** platform for automated data analysis.  
It features a modular architecture that intelligently processes user queries for both **web-based data scraping** and **complex database analysis**.

The platform dynamically generates and executes Python code on the fly using a **Large Language Model (LLM)**.  
It includes a self-healing mechanism to debug and retry failed code executions, making it highly resilient for real-world tasks.

---

## ğŸš€ Features

- **Dual-Workflow Architecture** â€” Handles both web scraping and database analysis tasks.
- **Dynamic Code Generation** â€” Creates tailored Python scripts per query instead of relying on fixed logic.
- **Self-Healing Execution** â€” Detects errors, requests LLM-based fixes, and retries automatically.
- **Robust Web Scraping** â€” Uses Playwright with stealth mode for JavaScript-heavy sites.
- **Intelligent Data Cleaning** â€” LLM-powered numeric data detection and formatting.
- **Extensible & Modular** â€” Easy to add new workflows or integrations.

---

## ğŸ“‚ Project Structure

root/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â””â”€â”€ api.py               # Core API logic
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # Workflow base classes
â”‚   â””â”€â”€ config.py            # Config & LLM setup
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_scraping.py      # Web scraping workflow
â”‚   â””â”€â”€ database_analysis.py # Database workflow
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py         # Project constants
â”‚   â”œâ”€â”€ duckdb_utils.py      # DuckDB helpers
â”‚   â””â”€â”€ prompts.py           # LLM prompts
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py          # API tests
â”œâ”€â”€ .env.example             # Example env vars
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md

```

---

## âš™ï¸ How It Works

### 1. **Web Scraping Workflow** (`multi_step_web_scraping`)
Triggered when a query contains a **URL**.

1. **Fetch Data** â€” Playwright scrapes full HTML.
2. **Extract & Clean** â€” Main table â†’ pandas DataFrame â†’ cleaned.
3. **Save CSV** â€” Stored as `temp_web_data.csv`.
4. **Generate Python Script** â€” LLM writes a pandas script for analysis.
5. **Execute & Self-Fix** â€” Runs script, retries on failure.
6. **Return Result** â€” Outputs JSON.

---

### 2. **Database Analysis Workflow** (`database_analysis`)
Triggered when the query references a **database** (e.g., S3 path).

1. **Create Data Summary** â€” Extracts schema & details.
2. **Generate Python Script** â€” LLM writes a DuckDB script.
3. **Execute & Self-Fix** â€” Runs script, retries on failure.
4. **Return Result** â€” Outputs JSON.

---

## ğŸ›  Setup & Installation

### âœ… Prerequisites

- Python 3.10+
- Google Gemini API Key

---

### ğŸ”§ Step-by-Step Setup

#### 1. Clone the Repository

```bash
git clone <your-repository-url>
cd "reshavs project"
````

#### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Configure Environment Variables

Rename `.env.example` â†’ `.env` and set your key:

```env
GEMINI_API_KEY="your_actual_gemini_api_key_here"
```

#### 5. Install Playwright Browsers

```bash
playwright install
```

---

### â–¶ï¸ Running the Application

```bash
uvicorn app.main:app --reload
```

App will be available at:
ğŸ“ `http://127.0.0.1:8000`

---

## ğŸ“¡ API Usage

### ğŸ”— Endpoint

```http
POST /api/
```

**Form Data:**

* `questions_txt` â†’ Path to `.txt` file containing your query

---

### ğŸ“„ Example â€” Web Scraping

**File**: `wiki_films_question.txt`

```text
Scrape the list of highest grossing films from Wikipedia...
URL: https://en.wikipedia.org/wiki/List_of_highest-grossing_films

1. How many $2 bn movies were released before 2000?
2. Which is the earliest film that grossed over $1.5 bn?
3. What's the correlation between Rank and Peak?
4. Draw a scatterplot of Rank and Peak with a red dotted regression line.
```

**Run:**

```bash
curl -X POST "http://127.0.0.1:8000/api/" \
     -F "questions_txt=@wiki_films_question.txt"
```

---

### ğŸ—ƒï¸ Example â€” Database Analysis

**File**: `high_court_question.txt`

```text
The Indian high court judgement dataset is located at:
s3://indian-high-court-judgments/...

Q1. Which high court disposed the most cases from 2019 - 2022?
Q2. Regression slope of date_of_registration - decision_date by year for court=33_10?
Q3. Scatterplot of year vs. delay days with regression line.
```

**Run:**

```bash
curl -X POST "http://127.0.0.1:8000/api/" \
     -F "questions_txt=@high_court_question.txt"
```